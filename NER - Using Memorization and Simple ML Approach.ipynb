{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NER using Memorization and Simple ML Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset from Kaggle: https://www.kaggle.com/abhinavwalia95/entity-annotated-corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source website: https://www.depends-on-the-definition.com/introduction-named-entity-recognition-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Reading the CSV Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/ner_dataset.csv\", encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.fillna(method=\"ffill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1048565</th>\n",
       "      <td>Sentence: 47958</td>\n",
       "      <td>impact</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048566</th>\n",
       "      <td>Sentence: 47958</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048567</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>Indian</td>\n",
       "      <td>JJ</td>\n",
       "      <td>B-gpe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048568</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>forces</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048569</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>said</td>\n",
       "      <td>VBD</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048570</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>they</td>\n",
       "      <td>PRP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048571</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>responded</td>\n",
       "      <td>VBD</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048572</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>to</td>\n",
       "      <td>TO</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048573</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048574</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>attack</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Sentence #       Word  POS    Tag\n",
       "1048565  Sentence: 47958     impact   NN      O\n",
       "1048566  Sentence: 47958          .    .      O\n",
       "1048567  Sentence: 47959     Indian   JJ  B-gpe\n",
       "1048568  Sentence: 47959     forces  NNS      O\n",
       "1048569  Sentence: 47959       said  VBD      O\n",
       "1048570  Sentence: 47959       they  PRP      O\n",
       "1048571  Sentence: 47959  responded  VBD      O\n",
       "1048572  Sentence: 47959         to   TO      O\n",
       "1048573  Sentence: 47959        the   DT      O\n",
       "1048574  Sentence: 47959     attack   NN      O"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = list(set(data[\"Word\"].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35178\n"
     ]
    }
   ],
   "source": [
    "n_words = len(words)\n",
    "\n",
    "print(n_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceGetter(object):\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.n_sent = 1\n",
    "        self.data = data\n",
    "        self.empty = False\n",
    "    \n",
    "    def get_next(self):\n",
    "        try:\n",
    "            s = self.data[self.data[\"Sentence #\"] == \"Sentence: {}\".format(self.n_sent)]\n",
    "            self.n_sent += 1\n",
    "            return s[\"Word\"].values.tolist(), s[\"POS\"].values.tolist(), s[\"Tag\"].values.tolist()    \n",
    "        except:\n",
    "            self.empty = True\n",
    "            return None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "getter = SentenceGetter(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent, pos, tag = getter.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Thousands', 'of', 'demonstrators', 'have', 'marched', 'through', 'London', 'to', 'protest', 'the', 'war', 'in', 'Iraq', 'and', 'demand', 'the', 'withdrawal', 'of', 'British', 'troops', 'from', 'that', 'country', '.']\n",
      "['NNS', 'IN', 'NNS', 'VBP', 'VBN', 'IN', 'NNP', 'TO', 'VB', 'DT', 'NN', 'IN', 'NNP', 'CC', 'VB', 'DT', 'NN', 'IN', 'JJ', 'NNS', 'IN', 'DT', 'NN', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'B-gpe', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "print(sent); print(pos); print(tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Memorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first simple idea and baseline might be to just remember the most common named entity for every word and predict that. In case we don’t know a word we just predict ‘O’. The following class does that. I implement it inheriting from a scikit-learn base classes to use the class with the inbuilt cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "\n",
    "class MemoryTagger(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        '''\n",
    "        Expects a list of words as X and a list of tags as y.\n",
    "        '''\n",
    "        voc = {}\n",
    "        self.tags = []\n",
    "        for x, t in zip(X, y):\n",
    "            if t not in self.tags:\n",
    "                self.tags.append(t)\n",
    "            if x in voc:\n",
    "                if t in voc[x]:\n",
    "                    voc[x][t] += 1\n",
    "                else:\n",
    "                    voc[x][t] = 1\n",
    "            else:\n",
    "                voc[x] = {t: 1}\n",
    "        self.memory = {}\n",
    "        for k, d in voc.items():\n",
    "            self.memory[k] = max(d, key=d.get)\n",
    "    \n",
    "    def predict(self, X, y=None):\n",
    "        '''\n",
    "        Predict the the tag from memory. If word is unknown, predict 'O'.\n",
    "        '''\n",
    "        return [self.memory.get(x, 'O') for x in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagger = MemoryTagger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagger.fit(sent, tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'B-gpe', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "print(tagger.predict(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O', 'B-geo', 'B-gpe']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger.tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, it looks like it basically works. Now we do a 5-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import cross_val_predict\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = data[\"Word\"].values.tolist()\n",
    "tags = data[\"Tag\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = cross_val_predict(estimator=MemoryTagger(), X=words, y=tags, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-art       0.20      0.05      0.09       402\n",
      "      B-eve       0.54      0.25      0.34       308\n",
      "      B-geo       0.78      0.85      0.81     37644\n",
      "      B-gpe       0.94      0.93      0.94     15870\n",
      "      B-nat       0.42      0.28      0.33       201\n",
      "      B-org       0.67      0.49      0.56     20143\n",
      "      B-per       0.78      0.65      0.71     16990\n",
      "      B-tim       0.87      0.77      0.82     20333\n",
      "      I-art       0.04      0.01      0.01       297\n",
      "      I-eve       0.39      0.12      0.18       253\n",
      "      I-geo       0.73      0.58      0.65      7414\n",
      "      I-gpe       0.62      0.45      0.52       198\n",
      "      I-nat       0.00      0.00      0.00        51\n",
      "      I-org       0.69      0.53      0.60     16784\n",
      "      I-per       0.73      0.65      0.69     17251\n",
      "      I-tim       0.58      0.13      0.21      6528\n",
      "          O       0.97      0.99      0.98    887908\n",
      "\n",
      "avg / total       0.94      0.95      0.94   1048575\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(y_pred=pred, y_true=tags)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks not so bad! The precision is quit reasonable, but as you might have guessed, the recall is pretty weak. This is due to the fact, that we cannot predict on words we don’t know. To overcome this issue, we will now introduce a simple machine learning model to predict the named entities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. A Simple ML Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do machine learning, we convert the data to a simple feature vector for every word and then use a random forest to classify the words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most simple feature map only contains information of the word itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_map(word):\n",
    "    '''Simple feature map.'''\n",
    "    return np.array([word.istitle(), word.islower(), word.isupper(), len(word),\n",
    "                     word.isdigit(),  word.isalpha()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [feature_map(w) for w in data[\"Word\"].values.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = cross_val_predict(RandomForestClassifier(n_estimators=20),\n",
    "                         X=words, y=tags, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-art       0.00      0.00      0.00       402\n",
      "      B-eve       0.00      0.00      0.00       308\n",
      "      B-geo       0.26      0.79      0.40     37644\n",
      "      B-gpe       0.26      0.06      0.09     15870\n",
      "      B-nat       0.00      0.00      0.00       201\n",
      "      B-org       0.65      0.17      0.27     20143\n",
      "      B-per       0.97      0.20      0.33     16990\n",
      "      B-tim       0.29      0.32      0.30     20333\n",
      "      I-art       0.00      0.00      0.00       297\n",
      "      I-eve       0.00      0.00      0.00       253\n",
      "      I-geo       0.00      0.00      0.00      7414\n",
      "      I-gpe       0.00      0.00      0.00       198\n",
      "      I-nat       0.00      0.00      0.00        51\n",
      "      I-org       0.36      0.03      0.06     16784\n",
      "      I-per       0.46      0.02      0.04     17251\n",
      "      I-tim       0.50      0.06      0.11      6528\n",
      "          O       0.97      0.98      0.97    887908\n",
      "\n",
      "avg / total       0.88      0.87      0.86   1048575\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abhishek\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(y_pred=pred, y_true=tags)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, that is not that good. This is expected, since the features lack a lot of information necessary for the decision. So now we enhance our simple features on the one hand by memory and on the other hand by using context information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "class FeatureTransformer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.memory_tagger = MemoryTagger()\n",
    "        self.tag_encoder = LabelEncoder()\n",
    "        self.pos_encoder = LabelEncoder()\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        words = X[\"Word\"].values.tolist()\n",
    "        self.pos = X[\"POS\"].values.tolist()\n",
    "        tags = X[\"Tag\"].values.tolist()\n",
    "        self.memory_tagger.fit(words, tags)\n",
    "        self.tag_encoder.fit(tags)\n",
    "        self.pos_encoder.fit(self.pos)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        def pos_default(p):\n",
    "            if p in self.pos:\n",
    "                return self.pos_encoder.transform([p])[0]\n",
    "            else:\n",
    "                return -1\n",
    "        \n",
    "        pos = X[\"POS\"].values.tolist()\n",
    "        words = X[\"Word\"].values.tolist()\n",
    "        out = []\n",
    "        for i in range(len(words)):\n",
    "            w = words[i]\n",
    "            p = pos[i]\n",
    "            if i < len(words) - 1:\n",
    "                wp = self.tag_encoder.transform(self.memory_tagger.predict([words[i+1]]))[0]\n",
    "                posp = pos_default(pos[i+1])\n",
    "            else:\n",
    "                wp = self.tag_encoder.transform(['O'])[0]\n",
    "                posp = pos_default(\".\")\n",
    "            if i > 0:\n",
    "                if words[i-1] != \".\":\n",
    "                    wm = self.tag_encoder.transform(self.memory_tagger.predict([words[i-1]]))[0]\n",
    "                    posm = pos_default(pos[i-1])\n",
    "                else:\n",
    "                    wm = self.tag_encoder.transform(['O'])[0]\n",
    "                    posm = pos_default(\".\")\n",
    "            else:\n",
    "                posm = pos_default(\".\")\n",
    "                wm = self.tag_encoder.transform(['O'])[0]\n",
    "            out.append(np.array([w.istitle(), w.islower(), w.isupper(), len(w), w.isdigit(), w.isalpha(),\n",
    "                                 self.tag_encoder.transform(self.memory_tagger.predict([w]))[0],\n",
    "                                 pos_default(p), wp, wm, posp, posm]))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = cross_val_predict(Pipeline([(\"feature_map\", FeatureTransformer()), \n",
    "                                   (\"clf\", RandomForestClassifier(n_estimators=20, n_jobs=3))]),\n",
    "                         X=data, y=tags, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = classification_report(y_pred=pred, y_true=tags)\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
