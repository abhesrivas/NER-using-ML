{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Named Entity Recognition using Bidirectional LSTMs\n",
    "\n",
    "In this notebook we train a bidirectional LSTM model for Named Entity Recognition on a Kaggle dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset from Kaggle: https://www.kaggle.com/abhinavwalia95/entity-annotated-corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source website: https://www.depends-on-the-definition.com/introduction-named-entity-recognition-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv(\"data/ner_dataset.csv\", encoding=\"latin1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.fillna(method=\"ffill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1048570</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>they</td>\n",
       "      <td>PRP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048571</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>responded</td>\n",
       "      <td>VBD</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048572</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>to</td>\n",
       "      <td>TO</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048573</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048574</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>attack</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Sentence #       Word  POS Tag\n",
       "1048570  Sentence: 47959       they  PRP   O\n",
       "1048571  Sentence: 47959  responded  VBD   O\n",
       "1048572  Sentence: 47959         to   TO   O\n",
       "1048573  Sentence: 47959        the   DT   O\n",
       "1048574  Sentence: 47959     attack   NN   O"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = list(set(data[\"Word\"].values))\n",
    "words.append(\"ENDPAD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35179"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_words = len(words); n_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = list(set(data[\"Tag\"].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_tags = len(tags); n_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have 47959 sentences containing 35178 different words with 17 different tags. We use the SentenceGetter class from last post to retrieve sentences with their labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceGetter(object):\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.n_sent = 1\n",
    "        self.data = data\n",
    "        self.empty = False\n",
    "        agg_func = lambda s: [(w, p, t) for w, p, t in zip(s[\"Word\"].values.tolist(),\n",
    "                                                           s[\"POS\"].values.tolist(),\n",
    "                                                           s[\"Tag\"].values.tolist())]\n",
    "        self.grouped = self.data.groupby(\"Sentence #\").apply(agg_func)\n",
    "        self.sentences = [s for s in self.grouped]\n",
    "    \n",
    "    def get_next(self):\n",
    "        try:\n",
    "            s = self.grouped[\"Sentence: {}\".format(self.n_sent)]\n",
    "            self.n_sent += 1\n",
    "            return s\n",
    "        except:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "getter = SentenceGetter(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = getter.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Thousands', 'NNS', 'O'), ('of', 'IN', 'O'), ('demonstrators', 'NNS', 'O'), ('have', 'VBP', 'O'), ('marched', 'VBN', 'O'), ('through', 'IN', 'O'), ('London', 'NNP', 'B-geo'), ('to', 'TO', 'O'), ('protest', 'VB', 'O'), ('the', 'DT', 'O'), ('war', 'NN', 'O'), ('in', 'IN', 'O'), ('Iraq', 'NNP', 'B-geo'), ('and', 'CC', 'O'), ('demand', 'VB', 'O'), ('the', 'DT', 'O'), ('withdrawal', 'NN', 'O'), ('of', 'IN', 'O'), ('British', 'JJ', 'B-gpe'), ('troops', 'NNS', 'O'), ('from', 'IN', 'O'), ('that', 'DT', 'O'), ('country', 'NN', 'O'), ('.', '.', 'O')]\n"
     ]
    }
   ],
   "source": [
    "print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = getter.sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"ggplot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist([len(s) for s in sentences], bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the use of neural nets (at least with keras, this is no theoretical reason) we need to use equal-lenght input sequences. So we are going to pad our sentences to a length of 50. But first we need dictionaries of words and tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 50\n",
    "word2idx = {w: i for i, w in enumerate(words)}\n",
    "tag2idx = {t: i for i, t in enumerate(tags)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26043"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2idx[\"Obama\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag2idx[\"B-geo\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we map the senctences to a sequence of numbers and then pad the sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "X = [[word2idx[w[0]] for w in s] for s in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pad_sequences(maxlen=max_len, sequences=X, padding=\"post\", value=n_words - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [[tag2idx[w[2]] for w in s] for s in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pad_sequences(maxlen=max_len, sequences=y, padding=\"post\", value=tag2idx[\"O\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For training the network we also need to change the labels y to categorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [to_categorical(i, num_classes=n_tags) for i in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can fit a LSTM network with an embedding layer. Note that we used the functional API of keras here, as it is more suitable for complicated architectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model, Input\n",
    "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = Input(shape=(max_len,))\n",
    "\n",
    "model = Embedding(input_dim=n_words, output_dim=50, input_length=max_len)(input)\n",
    "model = Dropout(0.5)(model)\n",
    "model = Bidirectional(LSTM(units=100, return_sequences=True, dropout=0.5, recurrent_dropout=0.25))(model)\n",
    "model = Dropout(0.5)(model)\n",
    "model = Bidirectional(LSTM(units=100, return_sequences=True, dropout=0.5, recurrent_dropout=0.25))(model)\n",
    "model = Dropout(0.5)(model)\n",
    "model = Bidirectional(LSTM(units=100, return_sequences=True, dropout=0.5, recurrent_dropout=0.25))(model)\n",
    "\n",
    "out = TimeDistributed(Dense(n_tags, activation=\"softmax\"))(model)  # softmax output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(input, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 23499 samples, validate on 10072 samples\n",
      "Epoch 1/5\n",
      "17408/23499 [=====================>........] - ETA: 1:23 - loss: 0.3073 - acc: 0.9321"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_tr, np.array(y_tr), batch_size=64, epochs=5, validation_split=0.3, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,12))\n",
    "plt.plot(hist[\"acc\"])\n",
    "plt.plot(hist[\"val_acc\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,12))\n",
    "plt.plot(hist[\"loss\"])\n",
    "plt.plot(hist[\"val_loss\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us look at some predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1005\n",
    "p = model.predict(np.array([X_te[i]]))\n",
    "p = np.argmax(p, axis=-1)\n",
    "true = np.argmax(y_te[i], -1)\n",
    "print(\"{:15} ({:5}): {}\".format(\"Word\", \"True\", \"Pred\"))\n",
    "for w, t, pred in zip(X_te[i], true, p[0]):\n",
    "    print(\"{:15}: {:5} {}\".format(words[w], tags[t], tags[pred]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
